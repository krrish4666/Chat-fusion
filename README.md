# ğŸ¤– Chat Fusion: Gemini + Llama with RAG

Chat Fusion is a **hybrid AI chatbot** that not only combines the power of **Google Gemini** and a **local Llama model** but also allows you to **chat with your own documents**.  
It is built with **Streamlit** and demonstrates how to build a Retrieval-Augmented Generation (RAG) pipeline to ground LLM responses in your specific data.

---

## ğŸ”— Repository
GitHub Repo: [Chat Fusion](https://github.com/krrish4666/Chat-fusion)

---

## âœ¨ Features
- ğŸ“„ **Chat with Your Documents (RAG)** - Upload your own PDF, TXT, or Markdown files.
  - Answers questions based *only* on the content of your documents.
  - Uses an in-memory FAISS vector store for fast and efficient retrieval.
- ğŸŒ **Gemini Integration** (2.5 Pro & Flash via Google GenAI API)  
- ğŸ’» **Local Model Support** with TinyLlama (runs on CPU/GPU)  
- âš¡ **Streaming responses** for Gemini (real-time typing effect)  
- ğŸ” **Tokenizer Explorer** â€“ compare Gemini vs Llama tokenization  
- ğŸ§  **Conversation memory** with adjustable history length  
- ğŸ§¹ **Clear chat history** option for fresh starts  

---

## ğŸ› ï¸ Tech Stack
- [Streamlit](https://streamlit.io/) â€“ frontend UI framework  
- [LangChain](https://www.langchain.com/) â€“ RAG pipeline orchestration  
- [Sentence-Transformers](https://www.sbert.net/) â€“ text embedding creation  
- [FAISS (Facebook AI)](https://faiss.ai/) â€“ efficient similarity search  
- [Google GenAI SDK](https://pypi.org/project/google-genai/) â€“ Gemini integration  
- [Transformers (Hugging Face)](https://huggingface.co/docs/transformers) â€“ local Llama model  
- [PyTorch](https://pytorch.org/) â€“ deep learning backend  

---

## âš¡ Quick Start

### 1. Clone the Repository
```bash
git clone https://github.com/krrish4666/Chat-fusion.git
cd Chat-fusion
```
### 2. Install Dependencies
```bash
pip install -r requirements.txt
```
### 3. Set up API Key

Export your Gemini API key as an environment variable:

Linux / macOS:
```bash
export GEMINI_API_KEY="your_api_key_here"
```
Windows PowerShell:
```bash
set GEMINI_API_KEY="your_api_key_here"
```

Alternatively, create a .env file and load it in app.py.

### 4. Run the App
```bash
streamlit run app.py
```

### ğŸ‘¤ Author

Built with â¤ï¸ by Krishna Yadav
